
<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>NaRCan</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://github.com/koi953215/NaRCan_page/blob/main/img/overview_combined.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1296">
    <meta property="og:image:height" content="840">
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://koi953215.github.io/NaRCan_page/"/>
    <meta property="og:title" content="NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing" />
    <meta property="og:description" content="Video editing approaches, especially through image-based diffusion models, have seen significant advancements but struggle with temporal consistency in video-to-video tasks. Existing models often fail to maintain sequence temporal consistency, disrupting frame transitions. To tackle this issue, this paper introduces NaRCan, a video editing framework that integrates a hybrid deformation field network with diffusion priors. Unlike conventional methods that generate a canonical image as a singular representation of video content, our approach ensures the production of high-quality, natural canonical images, which are crucial for downstream tasks like handwriting, style transfer, and dynamic segmentation. By leveraging a hybrid deformation field module and a sophisticated-designed scheduling method, NaRCan offers improved adaptability and superior editing capabilities across various video editing applications. Extensive experimental results show that our method outperforms existing approaches in producing coherent and high-quality video sequences. This work advances the state of video editing approaches and provides a robust solution for maintaining sequence temporal consistency using diffusion-based methods." />

    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="NaRCan: Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing" />
    <meta name="twitter:description" content="Video editing approaches, especially through image-based diffusion models, have seen significant advancements but struggle with temporal consistency in video-to-video tasks. Existing models often fail to maintain sequence temporal consistency, disrupting frame transitions. To tackle this issue, this paper introduces NaRCan, a video editing framework that integrates a hybrid deformation field network with diffusion priors. Unlike conventional methods that generate a canonical image as a singular representation of video content, our approach ensures the production of high-quality, natural canonical images, which are crucial for downstream tasks like handwriting, style transfer, and dynamic segmentation. By leveraging a hybrid deformation field module and a sophisticated-designed scheduling method, NaRCan offers improved adaptability and superior editing capabilities across various video editing applications. Extensive experimental results show that our method outperforms existing approaches in producing coherent and high-quality video sequences. This work advances the state of video editing approaches and provides a robust solution for maintaining sequence temporal consistency using diffusion-based methods." />
    <meta name="twitter:image" content="https://github.com/koi953215/NaRCan_page/blob/main/img/overview_combined.jpg" />


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’Š</text></svg>">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">
	<link rel="stylesheet" href="css/fontawesome.all.min.css">
	<link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-8ZERS5BVPS"></script>
  <script>
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());

	gtag('config', 'G-8ZERS5BVPS');
  </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script defer src="js/fontawesome.all.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.5.0/Chart.min.js"></script>

    <script src="js/app.js"></script>
    <script src="js/video_comparison.js"></script>
    <script src="js/synced_video_selector.js"></script>
</head>

<body style="padding: 1%; width: 100%">
    <div class="container" style="max-width: 1500px; margin: auto;" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>NaRCan</b>:<br>Natural Refined Canonical Image with Integration of Diffusion Prior for Video Editing</br> 
                <!-- <small>
                ICCV 2023 (Oral Presentation, Best Paper Finalist)
                </small> -->
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://koi953215.github.io/">
                            Ting-Hsuan Chen
                        </a>
                    </li>
                    <li>
                        <a href="">
                            Jiewen Chan
                        </a>
                    </li>
                    <li>
                        <a href="">
                            Shih-Han Yen
                        </a>
                    </li>
                    <li>
                        <a href="">
                            Hau-Shiang Shiu
                        </a>
                    </li>
                    <li>
                        <a href="">
                            Chang-Han Yeh
                        </a>
                    </li>
                    <li>
                        <a href="https://yulunalexliu.github.io/">
                            Yu-Lun Liu
                        </a>
                    </li>
                    </br>National Yang Ming Chiao Tung University
                </ul>
            </div>
        </div>


        <div class="row">
                <div class="col-md-6 col-md-offset-3 text-center">
                    <ul class="nav nav-pills nav-justified">
                        <li>
                            <a href="">
                            <image src="img/narcan_paper_image.jpg" height="60px">
                                <h4><strong>Paper</strong></h4>
                            </a>
                        </li>
                        <!-- <li>
                            <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">
                            <image src="img/youtube_icon.png" height="60px">
                                <h4><strong>Video</strong></h4>
                            </a>
                        </li> -->
                        <li>
                            <a href="https://github.com/jonbarron/camp_zipnerf">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code [coming soon]</strong></h4>
                            </a>
                        </li>
                    </ul>
                </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/teaser.mp4" type="video/mp4" />
                </video>
						</div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                    Video editing approaches, especially through image-based diffusion models, have seen significant advancements but struggle with temporal consistency in video-to-video tasks. Existing models often fail to maintain sequence temporal consistency, disrupting frame transitions. To tackle this issue, this paper introduces NaRCan, a video editing framework that integrates a hybrid deformation field network with diffusion priors. Unlike conventional methods that generate a canonical image as a singular representation of video content, our approach ensures the production of high-quality, natural canonical images, which are crucial for downstream tasks like handwriting, style transfer, and dynamic segmentation. By leveraging a hybrid deformation field module and a sophisticated-designed scheduling method, NaRCan offers improved adaptability and superior editing capabilities across various video editing applications. Extensive experimental results show that our method outperforms existing approaches in producing coherent and high-quality video sequences. This work advances the state of video editing approaches and provides a robust solution for maintaining sequence temporal consistency using diffusion-based methods.
                </p>
            </div>
        </div>

        <br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
				  <b><font color="#4472c4">NaR</font><font color="#ff0000">Can</font></b> = <font color="#4472c4"><b>Na</b>tural <b>R</b>efined</font> <font color="#ff0000"><b>Can</b>onical Image</font> with <font color="#ed7d31"><b>Diffusion Prior</b></font>
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="img/method_teaser.mp4" type="video/mp4" />
                </video>
                <!-- <image src="img/teaser.jpg" width=100% style="display: block; margin: auto;"></image> -->
                <br>
                <p class="text-justify">
                    <b>Video representation with diffusion prior.</b> Given an RGB video, we can represent the video using a canonical image. However, the canonical image and reconstruction training process focuses only on reconstruction quality and could produce an unnatural canonical image. This could cause problems with downstream tasks such as prompt-based video editing. In the bottom example, if the hand is distorted in the canonical image, the image editor, such as ControlNet, may not recognize it and could introduce an irrelevant object instead. In this paper, we propose introducing the <i>diffusion prior</i> from a LoRA fine-tuned diffusion model to the training pipeline and constraining the canonical image to be natural. Our method facilitates several downstream tasks, such as (a) video editing, (b) dynamic segmentation, and (c) video style transfer.
                </p>
            </div>
        </div>

        <br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Our proposed framework
                </h3>
                <image src="img/overview_combined.jpg" width=100% style="display: block; margin: auto;"></image>
                <br>
                <p class="text-justify">
                    Given an input video sequence, our method aims to represent the video with a <i>natural</i> canonical image, which is a crucial representation for versatile downstream applications. (a) First, we fine-tune the LoRA weights of a pre-trained latent diffusion model on the input frames. (b) Second, we represent the video using a canonical MLP and a deformation field, which consists of homography estimation and residual deformation MLP for non-rigid residual deformations. By relying entirely on the reconstruction loss, the canonical MLP often fails to represent a natural canonical image, causing problems for downstream applications. <i>E.g.</i>, image-to-image translation methods such as ControlNet may not be able to recognize that there is a train in the canonical image. (c) Therefore, we leverage the fine-tuned latent diffusion model to regularize and correct the unnatural canonical image into a natural one. Specifically, we sophistically design a noise scheduling corresponding to the frame reconstruction process. (d) The natural and artifacts-free canonical image can then be facilitated to various downstream tasks such as video style transfer, dynamic segmentation, and editing, such as adding handwritten characters.
                </p>
            </div>
        </div>
        
        <br>
            
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Diffusion prior for canonical image refinement
                </h3>
                <video id="v0" width="100%" autoplay loop muted controls>
                  <source src="img/dm_prior.mp4" type="video/mp4" />
                </video>
                <p class="text-justify">
                    (<em>Left</em>) Without diffusion prior to regularizing the canonical image, the training process relies only on the frame reconstruction and could sacrifice the faithfulness of the canonical image. (<em>Right</em>) Our fine-tuned diffusion prior effectively corrects the canonical image to faithfully represent the input frames and results in natural canonical images.
                </p>
            </div>
        </div>

        <br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Noise and diffusion prior update scheduling
                </h3>
                <image src="img/scheduling.jpg" width=100% style="display: block; margin: auto;"></image>
                <br>
                <video id="v0" width="100%" autoplay loop muted controls>
                    <source src="img/schedule.mp4" type="video/mp4" />
                </video>
                <p class="text-justify">
                    Initially, our model fits object outlines before the fields converge and without the diffusion prior, resulting in unnatural elements in the canonical image due to complex non-rigid objects. Upon introducing the diffusion prior with increased noise and update frequency, the model learns to generate natural, high-quality images, leading to convergence. Thus, the strength of noise and the update frequency will also decrease. Moreover, it's worth mentioning that update scheduling cuts training time from 4.8 hours to 20 minutes.
                </p>
            </div>
        </div>









        <br>
        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Text-guided video-to-video translation
                </h3><br>

                <div class="text-center ">
                    <ul class="nav nav-pills center-pills">
                        <li class="method-pill" data-value="input"
                            onclick="selectCompVideo('styletransfer', this, activeScenePill)"><a>Input</a></li>
                        <li class="method-pill" data-value="hash"
                            onclick="selectCompVideo('styletransfer', this, activeScenePill)"><a>Hashing-nvd</a></li>
                        <li class="method-pill active" data-value="codef"
                            onclick="selectCompVideo('styletransfer', this, activeScenePill)"><a>CoDeF</a></li>
                        <li class="method-pill" data-value="medm"
                            onclick="selectCompVideo('styletransfer', this, activeScenePill)"><a>MeDM</a></li>
                    </ul>
                </div>

                <script>
                    activeMethodPill = document.querySelector('.method-pill.active-pill');
                    activeScenePill = document.querySelector('.scene-pill.active-pill');
                    activeModePill = document.querySelector('.mode-pill.active-pill');
                </script>
                
                <div class="text-center">
                    <div class="video-container">
                        <video class="video" style="height: 280px; max-width: 100%;" m id="compVideo0" loop playsinline autoplay muted>
                            <source src="videos/styletransfer_bear_codef_vs_ours_video.mp4" />
                        </video>
                        <video class="video" style="height: 280px; max-width: 100%;" id="compVideo1" loop playsinline autoplay muted hidden>
                            <source src="videos/styletransfer_bear_codef_vs_ours_canonical.mp4" />
                        </video>
                    </div>
                    <div class="text-center" style="color: black;" id="mode-pills">
                        <div class="btn-group btn-group-sm">
                            <span class="btn btn-primary mode-pill active" data-value="video"
                                onclick="selectCompVideo('styletransfer', activeMethodPill, activeScenePill, null, this)">
                                Edited video
                            </span>
                            <span class="btn btn-primary mode-pill" data-value="canonical"
                                onclick="selectCompVideo('styletransfer', activeMethodPill, activeScenePill, null, this)">
                                Canonical image
                            </span>
                            <span class="btn btn-primary mode-pill" data-value="canonical_edit"
                                onclick="selectCompVideo('styletransfer', activeMethodPill, activeScenePill, null, this)">
                                Edited canonical image
                            </span>
                        </div>
                    </div>


                    <br>
                    <p class="text-justify" style="text-align: center;">
                        Text prompt: <span id="textPrompt"><strong>A Van Gogh-style cartoon bear walking in the forest.</strong></span><br>
                        Baseline method (left) vs NaRCan (right). Try selecting different methods and scenes!
                    </p>
                    <script>
                        video0 = document.getElementById("compVideo0");
                        video1 = document.getElementById("compVideo1");
                        video0.addEventListener('loadedmetadata', function() {
                            if (activeVidID == 0 && select){
                                video0.play();
                                // print video size
                                console.log(video0.videoWidth, video0.videoHeight);
                                video0.hidden = false;
                                video1.hidden = true;
                            }
                        });
                        video1.addEventListener('loadedmetadata', function() {
                            if (activeVidID == 1 && select){
                                video1.play();
                                // print video size
                                console.log(video1.videoWidth, video1.videoHeight);
                                video0.hidden = true;
                                video1.hidden = false;
                            }
                        });
                    </script>

                    <div class="pill-row scene-pills" id="scene-pills">
                        <span class="pill scene-pill active" data-value="bear" onclick="selectCompVideo('styletransfer', activeMethodPill, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/styletransfer_bear_thumbnail.jpg" alt="DTU/scan31" width="64">
                        </span>
                        <span class="pill scene-pill" data-value="boat" onclick="selectCompVideo('styletransfer', activeMethodPill, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/styletransfer_boat_thumbnail.jpg" alt="DTU/scan45" width="64">
                        </span>
                        <span class="pill scene-pill" data-value="hot-air-ballon" onclick="selectCompVideo('styletransfer', activeMethodPill, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/styletransfer_hot-air-ballon_thumbnail.jpg" alt="LLFF/fern" width="64">
                        </span>
                        <span class="pill scene-pill" data-value="overlook-the-ocean" onclick="selectCompVideo('styletransfer', activeMethodPill, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/styletransfer_overlook-the-ocean_thumbnail.jpg" alt="LLFF/horns" width="64">
                        </span>
                        <span class="pill scene-pill" data-value="shark-ocean" onclick="selectCompVideo('styletransfer', activeMethodPill, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/styletransfer_shark-ocean_thumbnail.jpg" alt="Re10K/sofa" width="64">
                        </span>
                    </div>

                    <script>
                        activeMethodPill = document.querySelector('.method-pill.active-pill');
                        activeScenePill = document.querySelector('.scene-pill.active-pill');
                        activeModePill = document.querySelector('.mode-pill.active-pill');
                    </script>
                </div>
            </div>
        </div>
        <br>
        



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Adding handwritten characters
                </h3><br>

                <div class="text-center ">
                    <ul class="nav nav-pills center-pills">
                        <li class="method-pill-handwrite" data-value="input"
                            onclick="selectCompVideoHandwrite('handwrite', this, activeScenePillHandwrite)"><a>Input</a></li>
                        <li class="method-pill-handwrite" data-value="hash"
                            onclick="selectCompVideoHandwrite('handwrite', this, activeScenePillHandwrite)"><a>Hashing-nvd</a></li>
                        <li class="method-pill-handwrite active" data-value="codef"
                            onclick="selectCompVideoHandwrite('handwrite', this, activeScenePillHandwrite)"><a>CoDeF</a></li>
                        <li class="method-pill-handwrite" data-value="medm"
                            onclick="selectCompVideoHandwrite('handwrite', this, activeScenePillHandwrite)"><a>MeDM</a></li>
                    </ul>
                </div>

                <script>
                    activeMethodPillHandwrite = document.querySelector('.method-pill-handwrite.active-pill');
                    activeScenePillHandwrite = document.querySelector('.scene-pill-handwrite.active-pill');
                    activeModePillHandwrite = document.querySelector('.mode-pill-handwrite.active-pill');
                </script>
                
                <div class="text-center">
                    <div class="video-container">
                        <video class="video" style="height: 280px; max-width: 100%;" m id="compVideo0_handwrite" loop playsinline autoplay muted>
                            <source src="videos/handwrite_train_codef_vs_ours_video.mp4" />
                        </video>
                        <video class="video" style="height: 280px; max-width: 100%;" id="compVideo1_handwrite" loop playsinline autoplay muted hidden>
                            <source src="videos/handwrite_train_codef_vs_ours_canonical.mp4" />
                        </video>
                    </div>
                    <div class="text-center" style="color: black;" id="mode-pills">
                        <div class="btn-group btn-group-sm">
                            <span class="btn btn-primary mode-pill-handwrite active" data-value="video"
                                onclick="selectCompVideoHandwrite('handwrite', activeMethodPillHandwrite, activeScenePillHandwrite, null, this)">
                                Edited video
                            </span>
                            <span class="btn btn-primary mode-pill-handwrite" data-value="canonical"
                                onclick="selectCompVideoHandwrite('handwrite', activeMethodPillHandwrite, activeScenePillHandwrite, null, this)">
                                Canonical image
                            </span>
                            <span class="btn btn-primary mode-pill-handwrite" data-value="canonical_edit"
                                onclick="selectCompVideoHandwrite('handwrite', activeMethodPillHandwrite, activeScenePillHandwrite, null, this)">
                                Edited canonical image
                            </span>
                        </div>
                    </div>


                    <br>
                    <p class="text-justify" style="text-align: center;">
                        Baseline method (left) vs NaRCan (right). Try selecting different methods and scenes!
                    </p>
                    
                    <div class="pill-row scene-pills-handwrite" id="scene-pills-handwrite">
                        <span class="pill scene-pill-handwrite active" data-value="train" onclick="selectCompVideoHandwrite('handwrite', activeMethodPillHandwrite, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/handwrite_train_thumbnail.jpg" alt="DTU/scan31" width="64">
                        </span>
                        <span class="pill scene-pill-handwrite" data-value="camel" onclick="selectCompVideoHandwrite('handwrite', activeMethodPillHandwrite, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/handwrite_camel_thumbnail.jpg" alt="DTU/scan45" width="64">
                        </span>
                        <span class="pill scene-pill-handwrite" data-value="cat" onclick="selectCompVideoHandwrite('handwrite', activeMethodPillHandwrite, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/handwrite_cat_thumbnail.jpg" alt="LLFF/fern" width="64">
                        </span>
                        <span class="pill scene-pill-handwrite" data-value="car-turn" onclick="selectCompVideoHandwrite('handwrite', activeMethodPillHandwrite, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/handwrite_car-turn_thumbnail.jpg" alt="LLFF/horns" width="64">
                        </span>
                        <span class="pill scene-pill-handwrite" data-value="tiger" onclick="selectCompVideoHandwrite('handwrite', activeMethodPillHandwrite, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/handwrite_tiger_thumbnail.jpg" alt="Re10K/sofa" width="64">
                        </span>
                    </div>

                    <script>
                        activeMethodPillHandwrite = document.querySelector('.method-pill-handwrite.active-pill');
                        activeScenePillHandwrite = document.querySelector('.scene-pill-handwrite.active-pill');
                        activeModePillHandwrite = document.querySelector('.mode-pill-handwrite.active-pill');
                    </script>
                </div>
            </div>
        </div>
        <br>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Segmentation-based tracking
                </h3><br>

                <div class="text-center ">
                    <ul class="nav nav-pills center-pills">
                        <li class="method-pill-dynamic" data-value="input"
                            onclick="selectCompVideoDynamic('dynamic', this, activeScenePillDynamic)"><a>Input</a></li>
                        <li class="method-pill-dynamic" data-value="hash"
                            onclick="selectCompVideoDynamic('dynamic', this, activeScenePillDynamic)"><a>Hashing-nvd</a></li>
                        <li class="method-pill-dynamic active" data-value="codef"
                            onclick="selectCompVideoDynamic('dynamic', this, activeScenePillDynamic)"><a>CoDeF</a></li>
                        <li class="method-pill-dynamic" data-value="medm"
                            onclick="selectCompVideoDynamic('dynamic', this, activeScenePillDynamic)"><a>MeDM</a></li>
                    </ul>
                </div>

                <script>
                    activeMethodPillDynamic = document.querySelector('.method-pill-dynamic.active-pill');
                    activeScenePillDynamic = document.querySelector('.scene-pill-dynamic.active-pill');
                    activeModePillDynamic = document.querySelector('.mode-pill-dynamic.active-pill');
                </script>
                
                <div class="text-center">
                    <div class="video-container">
                        <video class="video" style="height: 280px; max-width: 100%;" m id="compVideo0_dynamic" loop playsinline autoplay muted>
                            <source src="videos/dynamic_coral-reef_codef_vs_ours_video.mp4" />
                        </video>
                        <video class="video" style="height: 280px; max-width: 100%;" id="compVideo1_dynamic" loop playsinline autoplay muted hidden>
                            <source src="videos/dynamic_coral-reef_codef_vs_ours_canonical.mp4" />
                        </video>
                    </div>
                    <div class="text-center" style="color: black;" id="mode-pills">
                        <div class="btn-group btn-group-sm">
                            <span class="btn btn-primary mode-pill-dynamic active" data-value="video"
                                onclick="selectCompVideoDynamic('dynamic', activeMethodPillDynamic, activeScenePillDynamic, null, this)">
                                Edited video
                            </span>
                            <span class="btn btn-primary mode-pill-dynamic" data-value="canonical"
                                onclick="selectCompVideoDynamic('dynamic', activeMethodPillDynamic, activeScenePillDynamic, null, this)">
                                Canonical image
                            </span>
                            <span class="btn btn-primary mode-pill-dynamic" data-value="canonical_edit"
                                onclick="selectCompVideoDynamic('dynamic', activeMethodPillDynamic, activeScenePillDynamic, null, this)">
                                Segmentation mask
                            </span>
                        </div>
                    </div>


                    <br>
                    <p class="text-justify" style="text-align: center;">
                        Baseline method (left) vs NaRCan (right). The segmentation mask is acquired using Segment Anything (SAM) based on the learned canonical image and propagated to the sequence. Try selecting different methods and scenes!
                    </p>
                    
                    <div class="pill-row scene-pills-dynamic" id="scene-pills-dynamic">
                        <span class="pill scene-pill-dynamic active" data-value="coral-reef" onclick="selectCompVideoDynamic('dynamic', activeMethodPillDynamic, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/dynamic_coral-reef_thumbnail.jpg" alt="DTU/scan31" width="64">
                        </span>
                        <span class="pill scene-pill-dynamic" data-value="butterfly" onclick="selectCompVideoDynamic('dynamic', activeMethodPillDynamic, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/dynamic_butterfly_thumbnail.jpg" alt="DTU/scan45" width="64">
                        </span>
                        <span class="pill scene-pill-dynamic" data-value="two-swan" onclick="selectCompVideoDynamic('dynamic', activeMethodPillDynamic, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/dynamic_two-swan_thumbnail.jpg" alt="LLFF/fern" width="64">
                        </span>
                        <span class="pill scene-pill-dynamic" data-value="woman-drink" onclick="selectCompVideoDynamic('dynamic', activeMethodPillDynamic, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/dynamic_woman-drink_thumbnail.jpg" alt="LLFF/horns" width="64">
                        </span>
                        <span class="pill scene-pill-dynamic" data-value="surf" onclick="selectCompVideoDynamic('dynamic', activeMethodPillDynamic, this, 3)">
                            <img class="thumbnail-img" src="thumbnails/dynamic_surf_thumbnail.jpg" alt="Re10K/sofa" width="64">
                        </span>
                    </div>

                    <script>
                        activeMethodPillDynamic = document.querySelector('.method-pill-dynamic.active-pill');
                        activeScenePillDynamic = document.querySelector('.scene-pill-dynamic.active-pill');
                        activeModePillDynamic = document.querySelector('.mode-pill-dynamic.active-pill');
                    </script>
                </div>
            </div>
        </div>
        <br>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    User study
                </h3>
                <image src="img/user_study.jpg" width=100% style="display: block; margin: auto;"></image>
                <p class="text-justify">
                    Our method achieves the highest user preference ratios across all three aspects, compared with MeDM, CoDeF, Hashing-nvd.
                </p>
            </div>
        </div><br>









        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <div class="form-group col-md-10 col-md-offset-1">
                    <textarea id="bibtex" class="form-control" readonly>
@article{chen2024narcan,
    title={NaRCan: Natural Refined Canonical Image with 
           Integration of Diffusion Prior for Video Editing},
    author={Ting-Hsuan Chen and Jiewen Chan and Shih-Han Yen and 
            Hau-Shiang Shiu and Chang-Han Yeh and Yu-Lun Liu},
    journal={arXiv},
    year={2024}
}</textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                This research was funded by the National Science and Technology Council, Taiwan, under Grants NSTC 112-2222-E-A49-004-MY2. The authors are grateful to Google, NVIDIA, and MediaTek Inc. for generous donations. Yu-Lun Liu acknowledges the Yushan Young Fellow Program by the MOE in Taiwan.
                    <br><br>
                The website template was borrowed from <a href="http://mgharbi.com/">MichaÃ«l Gharbi</a> and <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
